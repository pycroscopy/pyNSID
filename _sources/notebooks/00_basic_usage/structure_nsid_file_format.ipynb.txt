{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of NSID file format\n",
    "\n",
    "*Author: Gerd Duscher*\n",
    "\n",
    "*Date: December 2020*\n",
    "update: \n",
    "- *Gerd Duscher 01/2021 (compatibility to pyNSID version 0.0.2)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pyNSID file format is based on ``h5py`` package for the ``hdf5`` file system.\n",
    "\n",
    "The NSID conventions implemented on top of the ``hdf5`` file format are easily accessible through the pyNSID  package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with standard imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.4\n"
     ]
    }
   ],
   "source": [
    "# Ensure python 3 compatibility:\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "# we will also need a sidpy package\n",
    "\n",
    "sys.path.insert(0,'../../../sidpy/')\n",
    "import sidpy \n",
    "\n",
    "print(sidpy.__version__)\n",
    "sys.path.insert(0,'../../')\n",
    "import pyNSID as nsid\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"numpy.core.fromnumeric\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"pyNSID.io.nsi_reader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ new_spectrum\n",
      "      ------------\n",
      "      ├ __dict__\n",
      "        --------\n",
      "      ├ _axes\n",
      "        -----\n",
      "      ├ _metadata\n",
      "        ---------\n",
      "      ├ bias\n",
      "      ├ metadata\n",
      "        --------\n",
      "      ├ new_spectrum\n",
      "      ├ x\n",
      "      ├ y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../..\\pyNSID\\io\\hdf_utils.py:351: FutureWarning: validate_h5_dimension may be removed in a future version\n",
      "  warn('validate_h5_dimension may be removed in a future version',\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    os.remove('test2.hf5') \n",
    "    print('removed file: test2.hf')\n",
    "except:\n",
    "    pass\n",
    "dataset = sidpy.Dataset.from_array(np.random.random([4, 5, 10]), name='new')\n",
    "dataset.data_type = 'SPECTRAL_IMAGE'\n",
    "dataset.units = 'nA'\n",
    "dataset.quantity = 'Current'\n",
    "\n",
    "dataset.metadata={'this': 'is just a random dataset'}\n",
    "\n",
    "dataset.set_dimension(0, sidpy.Dimension(np.arange(dataset.shape[0]), 'x',\n",
    "                                        units='nm', quantity='Length',\n",
    "                                        dimension_type='spatial'))\n",
    "dataset.set_dimension(1, sidpy.Dimension(np.linspace(-2, 2, num=dataset.shape[1], endpoint=True), 'y', \n",
    "                                        units='nm', quantity='Length',\n",
    "                                        dimension_type='spatial'))\n",
    "dataset.set_dimension(2, sidpy.Dimension(np.sin(np.linspace(0, 2 * np.pi, num=dataset.shape[2])), 'bias',\n",
    "                                        units='mV', quantity='Voltage',\n",
    "                                        dimension_type='spectral'))\n",
    "\n",
    "hf = h5py.File(\"test2.hf5\", 'a')\n",
    "if 'Measurement_000' in hf:\n",
    "    del hf['Measurement_000']\n",
    "hf.create_group('Measurement_000/Channel_000')\n",
    "nsid.hdf_io.write_nsid_dataset(dataset, hf['Measurement_000/Channel_000'], main_data_name=\"new_spectrum\")\n",
    "sidpy.hdf_utils.print_tree(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Channel_000']>\n"
     ]
    }
   ],
   "source": [
    "hdf5_file = h5py.File(\"test2.hf5\", 'r+')\n",
    "print(hdf5_file[\"Measurement_000\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We really do normally not care about the underlying structure as the NSID reader is taking care of everything.\n",
    "\n",
    "The NSID reader will return a sidpy dataset, which we then can plot, analyze, modify, and write back to the h5py file in pyNSID format.\n",
    "\n",
    "We can read all of them or just a specific `directory` in this hirachical data file (hdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 1.60 kB </td> <td> 1.60 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (4, 5, 10) </td> <td> (4, 5, 10) </td></tr>\n",
       "    <tr><th> Count </th><td> 1 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"208\" height=\"138\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"60\" x2=\"38\" y2=\"88\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"60\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"88\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 38.23529411764706,28.235294117647058 38.23529411764706,88.23529411764706 10.0,60.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"158\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"158\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 158.23529411764707,28.235294117647058 38.23529411764706,28.235294117647058\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"158\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"88\" x2=\"158\" y2=\"88\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"88\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"158\" y1=\"28\" x2=\"158\" y2=\"88\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"38.23529411764706,28.235294117647058 158.23529411764707,28.235294117647058 158.23529411764707,88.23529411764706 38.23529411764706,88.23529411764706\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"98.235294\" y=\"108.235294\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10</text>\n",
       "  <text x=\"178.235294\" y=\"58.235294\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,178.235294,58.235294)\">5</text>\n",
       "  <text x=\"14.117647\" y=\"94.117647\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,14.117647,94.117647)\">4</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "sidpy.Dataset of type SPECTRAL_IMAGE with:\n",
       " dask.array<generic, shape=(4, 5, 10), dtype=float64, chunksize=(4, 5, 10), chunktype=numpy.ndarray>\n",
       " data contains: Current (nA)\n",
       " and Dimensions: \n",
       "x:  Length (nm) of size (4,)\n",
       "y:  Length (nm) of size (5,)\n",
       "bias:  Voltage (mV) of size (10,)\n",
       " with metadata: ['this']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsid_reader = nsid.NSIDReader(\"test2.hf5\")\n",
    "sidpy_dataset = nsid_reader.read()[0]\n",
    "sidpy_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration the structure of the pyNSID data format\n",
    "\n",
    "We will use a sidpy function to plot the tree of the hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ new_spectrum\n",
      "      ------------\n",
      "      ├ __dict__\n",
      "        --------\n",
      "      ├ _axes\n",
      "        -----\n",
      "      ├ _metadata\n",
      "        ---------\n",
      "      ├ bias\n",
      "      ├ metadata\n",
      "        --------\n",
      "      ├ new_spectrum\n",
      "      ├ x\n",
      "      ├ y\n"
     ]
    }
   ],
   "source": [
    "sidpy.hdf_utils.print_tree(hdf5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a suggested convention we use Measurement_000 as the first directory to store different datasets that belong together. So ``Measurement_000`` is a ``h5py.Group``. Which contains several other ``h5py.Group``s which all start with ``Channel_``.\n",
    "\n",
    "All directories are numbered and there is a function in ``sidpy`` to automatically increase this number for a new group for convenience (*sidpy.hdf.prov_utils.create_indexed_group*).\n",
    "\n",
    "The different ``Channels`` could be for example reference data, or  simultaneously acquired datasets.\n",
    "\n",
    "The results would be logged with each individual dataset in its channel.\n",
    "\n",
    "The names of directories of results should start with `Log_` or `Result_`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Channel Group\n",
    "\n",
    "The channel group contains several other ``h5py.Group``s and ``h5py.Datasets``.\n",
    "\n",
    "Every attribute of a stored ``sidpy`` dataset will be a group and the ``attributes`` of those groups are the dictionaries of these attributes  of ``sidpy`` datasets.\n",
    "    \n",
    "For example ``metadata`` is an attribute of the sidpy dataset.\n",
    "\n",
    "So there will be an ``h5py.Group`` with the name ``metadata``  and the ``attributes`` of that group contain the dictionary of the original ``metadata`` attribute of the ``sidpy`` dataset.\n",
    "\n",
    "The attributes of a ``h5py.Group`` can be accessed with ``attrs`` and is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['__dict__', '_axes', '_metadata', 'bias', 'metadata', 'new_spectrum', 'x', 'y']>\n",
      "{'this': 'is just a random dataset'}\n",
      "{'this': 'is just a random dataset'}\n"
     ]
    }
   ],
   "source": [
    "print( hdf5_file['Measurement_000/Channel_000/new_spectrum'].keys())\n",
    "\n",
    "print(dict(hdf5_file['Measurement_000/Channel_000/new_spectrum/metadata'].attrs))\n",
    "print(sidpy_dataset.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions of a dataset\n",
    "\n",
    "A ``h5py.Dataset`` can have the dimensions ``attached`` to the dataset. \n",
    "The `attributes` of the dataset has actually the dimension labels stored and those dimensions are datasets in the same ``Directory``.\n",
    "\n",
    "In the list of attributes of the main dataset we can see that a few other mandatorty items of a sidpy datasets (like: data_type) are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine_id: MSE-Tab01.utk.tennessee.edu\n",
      "platform: Windows-10-10.0.19041-SP0\n",
      "pyNSID_version: 0.0.2\n",
      "sidpy_version: 0.0.4\n",
      "timestamp: 2021_01_15-17_13_39\n"
     ]
    }
   ],
   "source": [
    "for k, v in (hdf5_file['Measurement_000/Channel_000/new_spectrum'].attrs).items():\n",
    "    print(\"{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ``[]'x' 'y' 'bias']`` are the labels of the Dimensions and those datasets are actually visible in the Channel.\n",
    "\n",
    "The ``attributes`` of those dimensional ``h5py.Datasets`` contain the addtionional information required by ``pyNSID`` and ``sidpy`` in their attributes and (in captial letters) the information of the ``hdf5`` dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CLASS': b'DIMENSION_SCALE', 'NAME': b'x', 'REFERENCE_LIST': array([(<HDF5 object reference>, 0)],\n",
      "      dtype={'names':['dataset','dimension'], 'formats':['O','<i4'], 'offsets':[0,8], 'itemsize':16}), 'dimension_type': 'SPATIAL', 'name': 'x', 'quantity': 'Length', 'units': 'nm'}\n"
     ]
    }
   ],
   "source": [
    "print(dict(hdf5_file['Measurement_000/Channel_000/new_spectrum/x'].attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "NSID data format is available through the pyNSID package. The format is an extension of the hdf5 format accessible through the h5py package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
